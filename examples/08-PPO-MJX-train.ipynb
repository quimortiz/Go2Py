{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from go2_env import Go2Env\n",
    "import jax\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Callable, NamedTuple, Optional, Union, List\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "import jax.numpy as jp\n",
    "import os\n",
    "import functools\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from orbax import checkpoint as ocp\n",
    "from flax.training import orbax_utils\n",
    "from etils import epath\n",
    "from brax.io import  model as brax_model\n",
    "from datetime import datetime  \n",
    "from matplotlib.backends.backend_pdf import PdfPages \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reference: mjx tutorial on mujoco github\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "xla_flags = os.environ.get(\"XLA_FLAGS\", \"\")\n",
    "xla_flags += \" --xla_gpu_triton_gemm_any=True\"\n",
    "os.environ[\"XLA_FLAGS\"] = xla_flags\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "\n",
    "# Use the 'tab20' colormap\n",
    "plt.rc('axes', prop_cycle=plt.cycler('color', plt.cm.tab20.colors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go2_env =  Go2Env()\n",
    "prng = jax.random.PRNGKey(0)\n",
    "state =  go2_env.reset(prng) \n",
    "tic = time.time()\n",
    "step_jit = jax.jit(go2_env.step)\n",
    "toc = time.time()\n",
    "print(\"elapsed time jit\", toc - tic)\n",
    "num_steps = 100\n",
    "ctrl = jp.zeros(12)\n",
    "states = []\n",
    "tic = time.time()\n",
    "for i in range(num_steps): \n",
    "    state = step_jit(state, ctrl)\n",
    "    states.append(state.pipeline_state)\n",
    "toc = time.time()\n",
    "print(f\"elapsed time {num_steps} steps\", toc - tic)\n",
    "\n",
    "tic = time.time()\n",
    "frames = go2_env.render(states, camera=\"track\")\n",
    "toc = time.time()\n",
    "print(\"elapsed time render\", toc - tic)\n",
    "print(\"done!\")\n",
    "media.show_video(frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a normal simluation in mujoco.\n",
    "frames = []\n",
    "mj_model =  mujoco.MjModel.from_xml_path('../Go2Py/assets/mujoco/go2.xml')\n",
    "mj_data = mujoco.MjData(mj_model)\n",
    "\n",
    "mj_data.qpos[:] = mj_model.keyframe('home').qpos\n",
    "mj_data.qvel = np.zeros(mj_model.nv)\n",
    "mujoco.mj_forward(mj_model, mj_data)\n",
    "print(mj_data.body('base').xpos)\n",
    "num_steps = 1000\n",
    "ctrl = np.zeros(mj_model.nu)\n",
    "kp = 35\n",
    "kd = .5\n",
    "renderer = mujoco.Renderer(mj_model)\n",
    "save_one_every = 30\n",
    "for i in range(num_steps):\n",
    "    q = mj_data.qpos[7:]\n",
    "    dq = mj_data.qvel[6:]\n",
    "    q_des = mj_model.keyframe('home').qpos[7:] + ctrl\n",
    "    tau = kp * ( q_des - q) - kd * dq\n",
    "    mj_data.ctrl[:] = tau\n",
    "    mujoco.mj_step(mj_model, mj_data)\n",
    "    print(\"q\", q)\n",
    "    if i % save_one_every == 0:\n",
    "        renderer.update_scene(mj_data,camera=\"track\")\n",
    "        pixels = renderer.render()\n",
    "        frames.append(pixels)\n",
    "renderer.close()\n",
    "media.show_video(frames, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torso idx\n",
      "1\n",
      "torso idx\n",
      "1\n",
      "torso idx\n",
      "1\n",
      "step: 0  reward: 0.525\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_0.png\n",
      "step: 1064960  reward: 0.655\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_1064960.png\n",
      "[Checkpoint] Saved at step 1064960 to /tmp/quadrupred_joystick/ckpts/1064960\n",
      "saving params to \n",
      "[Evaluation] Episode terminated at step 57\n",
      "render\n",
      "elapsed time 0.47868800163269043\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_1064960.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_1064960.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_1064960.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 2129920  reward: 1.429\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_2129920.png\n",
      "[Checkpoint] Saved at step 2129920 to /tmp/quadrupred_joystick/ckpts/2129920\n",
      "saving params to \n",
      "[Evaluation] Episode terminated at step 82\n",
      "render\n",
      "elapsed time 0.25670623779296875\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_2129920.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_2129920.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_2129920.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 3194880  reward: 1.882\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_3194880.png\n",
      "[Checkpoint] Saved at step 3194880 to /tmp/quadrupred_joystick/ckpts/3194880\n",
      "saving params to \n",
      "render\n",
      "elapsed time 0.3468198776245117\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_3194880.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_3194880.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_3194880.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 4259840  reward: nan\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_4259840.png\n",
      "[Checkpoint] Saved at step 4259840 to /tmp/quadrupred_joystick/ckpts/4259840\n",
      "saving params to \n",
      "render\n",
      "elapsed time 0.3427999019622803\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_4259840.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_4259840.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_4259840.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 5324800  reward: nan\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_5324800.png\n",
      "[Checkpoint] Saved at step 5324800 to /tmp/quadrupred_joystick/ckpts/5324800\n",
      "saving params to \n",
      "render\n",
      "elapsed time 0.3969578742980957\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_5324800.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_5324800.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_5324800.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 6389760  reward: nan\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_6389760.png\n",
      "[Checkpoint] Saved at step 6389760 to /tmp/quadrupred_joystick/ckpts/6389760\n",
      "saving params to \n",
      "render\n",
      "elapsed time 0.346996545791626\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_6389760.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_6389760.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_6389760.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 7454720  reward: nan\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_7454720.png\n",
      "[Checkpoint] Saved at step 7454720 to /tmp/quadrupred_joystick/ckpts/7454720\n",
      "saving params to \n",
      "render\n",
      "elapsed time 0.363480806350708\n",
      "done!\n",
      "[Video] Saved video to /tmp/quadrupred_joystick/walk_7454720.mp4\n",
      "[Plot] Added all functions plot to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_7454720.pdf\n",
      "[Plot] Saved all reward plots to PDF: /tmp/quadrupred_joystick/plots/reward_plots_step_7454720.pdf\n",
      "[Evaluation] Reward plotting completed.\n",
      "step: 8519680  reward: nan\n",
      "[Evaluation] Saving plot to /tmp/quadrupred_joystick/plots/plot_8519680.png\n",
      "[Checkpoint] Saved at step 8519680 to /tmp/quadrupred_joystick/ckpts/8519680\n",
      "saving params to \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 304\u001b[0m\n\u001b[1;32m    300\u001b[0m times \u001b[38;5;241m=\u001b[39m [datetime\u001b[38;5;241m.\u001b[39mnow()]\n\u001b[1;32m    301\u001b[0m max_y, min_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 304\u001b[0m make_inference_fn, params, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/brax/training/agents/ppo/train.py:473\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(environment, num_timesteps, episode_length, action_repeat, num_envs, max_devices_per_host, num_eval_envs, learning_rate, entropy_cost, discounting, seed, unroll_length, batch_size, num_minibatches, num_updates_per_batch, num_evals, num_resets_per_eval, normalize_observations, reward_scaling, clipping_epsilon, gae_lambda, deterministic_eval, network_factory, progress_fn, normalize_advantage, eval_env, policy_params_fn, randomization_fn, restore_checkpoint_path)\u001b[0m\n\u001b[1;32m    469\u001b[0m     progress_fn(current_step, metrics)\n\u001b[1;32m    470\u001b[0m     params \u001b[38;5;241m=\u001b[39m _unpmap(\n\u001b[1;32m    471\u001b[0m         (training_state\u001b[38;5;241m.\u001b[39mnormalizer_params, training_state\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    472\u001b[0m     )\n\u001b[0;32m--> 473\u001b[0m     \u001b[43mpolicy_params_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m total_steps \u001b[38;5;241m=\u001b[39m current_step\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m total_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_timesteps\n",
      "Cell \u001b[0;32mIn[2], line 114\u001b[0m, in \u001b[0;36mpolicy_params_fn\u001b[0;34m(current_step, make_policy, params)\u001b[0m\n\u001b[1;32m    112\u001b[0m act_rng, rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(rng)\n\u001b[1;32m    113\u001b[0m ctrl, _ \u001b[38;5;241m=\u001b[39m jit_inference_fn(state\u001b[38;5;241m.\u001b[39mobs, act_rng)\n\u001b[0;32m--> 114\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mjit_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m rollout\u001b[38;5;241m.\u001b[39mappend(state\u001b[38;5;241m.\u001b[39mpipeline_state)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Collect rewards\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/mujoco/mjx/_src/dataclasses.py:81\u001b[0m, in \u001b[0;36mdataclass.<locals>.clz_from_iterable\u001b[0;34m(meta, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m   meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(to_meta(f, x) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m meta_fields)\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data, meta\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclz_from_iterable\u001b[39m(meta, data):\n\u001b[1;32m     83\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_meta\u001b[39m(field, meta):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m field\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets start the training loop\n",
    "def domain_randomize(sys, rng):\n",
    "    \"\"\"Randomizes the mjx.Model.\"\"\"\n",
    "\n",
    "    @jax.vmap\n",
    "    def rand(rng):\n",
    "        _, key = jax.random.split(rng, 2)\n",
    "        # friction\n",
    "        friction = jax.random.uniform(key, (1,), minval=0.5, maxval=1.3)\n",
    "        friction = sys.geom_friction.at[:, 0].set(friction)\n",
    "        # todo: randomize something else!\n",
    "        return friction\n",
    "\n",
    "    friction = rand(rng)\n",
    "\n",
    "    in_axes = jax.tree_util.tree_map(lambda x: None, sys)\n",
    "    in_axes = in_axes.tree_replace({\"geom_friction\": 0})\n",
    "\n",
    "    sys = sys.tree_replace(\n",
    "        {\n",
    "            \"geom_friction\": friction,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return sys, in_axes\n",
    "\n",
    "\n",
    "# NOTE: parameters that are not inside the mujoco model are randomized by setting\n",
    "# a flag to the environment.\n",
    "\n",
    "\n",
    "env_name = \"go2\"\n",
    "Fs = .5\n",
    "mu_v = .3\n",
    "env = Go2Env(randomize_custom_params=True, Fs=Fs, mu_v=mu_v)\n",
    "eval_env = Go2Env(randomize_custom_params=True, Fs=Fs, mu_v=mu_v)\n",
    "eval_env_local = Go2Env(randomize_custom_params=True, Fs=Fs, mu_v=mu_v)\n",
    "reset = eval_env_local.reset\n",
    "jit_step = jax.jit(eval_env_local.step)\n",
    "render = eval_env_local.render\n",
    "dt = eval_env.dt\n",
    "\n",
    "plot_path = epath.Path(\"/tmp/quadrupred_joystick/plots\")\n",
    "ckpt_path = epath.Path(\"/tmp/quadrupred_joystick/ckpts\")\n",
    "video_path = epath.Path(\"/tmp/quadrupred_joystick/\")\n",
    "ckpt_path.mkdir(parents=True, exist_ok=True)\n",
    "video_path.mkdir(parents=True, exist_ok=True)\n",
    "plot_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "make_networks_factory = functools.partial(\n",
    "    ppo_networks.make_ppo_networks, policy_hidden_layer_sizes=(128, 128, 128, 128)\n",
    ")\n",
    "\n",
    "\n",
    "def policy_params_fn(current_step, make_policy, params):\n",
    "    \"\"\"\n",
    "    Callback function to save policy checkpoints and generate evaluation videos.\n",
    "\n",
    "    Args:\n",
    "        current_step (int): The current training step.\n",
    "        make_policy (Callable): Function to create the policy network.\n",
    "        params (PyTree): The current parameters of the policy network.\n",
    "    \"\"\"\n",
    "    # Save the current policy parameters as a checkpoint\n",
    "    orbax_checkpointer = ocp.PyTreeCheckpointer()\n",
    "    save_args = orbax_utils.save_args_from_target(params)\n",
    "    path = ckpt_path / f\"{current_step}\"\n",
    "    orbax_checkpointer.save(path, params, force=True, save_args=save_args)\n",
    "    print(f\"[Checkpoint] Saved at step {current_step} to {path}\")\n",
    "\n",
    "    print(\"saving params to \")\n",
    "    model_path = f\"/tmp/mjx_brax_quadruped_policy_{current_step}\"\n",
    "    brax_model.save_params(model_path, params)\n",
    "\n",
    "    # Create an inference function from the current parameters\n",
    "\n",
    "    # _params = _unpmap(\n",
    "    #       (training_state.normalizer_params, training_state.params.policy))\n",
    "\n",
    "    inference_fn = make_policy((params[0], params[1].policy))\n",
    "    jit_inference_fn = jax.jit(inference_fn)  # is this necessary?\n",
    "\n",
    "    # @markdown Commands **only used for Barkour Env**:\n",
    "    x_vel = 1.0  # @param {type: \"number\"}\n",
    "    y_vel = 0.0  # @param {type: \"number\"}\n",
    "    ang_vel = -0.5  # @param {type: \"number\"}\n",
    "\n",
    "    the_command = jp.array([x_vel, y_vel, ang_vel])\n",
    "\n",
    "    # initialize the state\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    state = reset(rng)\n",
    "    state.info[\"command\"] = the_command\n",
    "    rollout = [state.pipeline_state]\n",
    "\n",
    "    # grab a trajectory\n",
    "    n_steps = 500\n",
    "    render_every = 2\n",
    "\n",
    "    # -------------------- 5. Initialize Reward Containers --------------------\n",
    "    total_rewards = []  # To store total reward per step\n",
    "    reward_components = {\n",
    "        k: [] for k in state.info[\"rewards\"].keys()\n",
    "    }  # To store individual reward components\n",
    "\n",
    "    # -------------------- 6. Perform Rollout --------------------\n",
    "\n",
    "    # print(\"rollout\")\n",
    "    for i in range(n_steps):\n",
    "        # print(\"i\", i)\n",
    "        act_rng, rng = jax.random.split(rng)\n",
    "        ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "        state = jit_step(state, ctrl)\n",
    "        rollout.append(state.pipeline_state)\n",
    "\n",
    "        # Collect rewards\n",
    "        total_rewards.append(state.reward)  # Total reward for this step\n",
    "        for k, v in state.info[\"rewards\"].items():\n",
    "            reward_components[k].append(v)\n",
    "\n",
    "        if state.done:\n",
    "            print(f\"[Evaluation] Episode terminated at step {i}\")\n",
    "            break\n",
    "\n",
    "    # Render the rollout frames\n",
    "    print(\"render\")\n",
    "    tic = time.time()\n",
    "    frames = render(rollout[::render_every], camera=\"track\")\n",
    "    toc = time.time()\n",
    "    print(\"elapsed time\", toc - tic)\n",
    "    print(\"done!\")\n",
    "\n",
    "    # Define the video filename\n",
    "    video_filename = video_path / f\"walk_{current_step}.mp4\"\n",
    "\n",
    "    # Save the video using MediaPy\n",
    "    media.write_video(\n",
    "        video_filename.as_posix(), frames, fps=int(1.0 / dt / render_every)\n",
    "    )\n",
    "    print(f\"[Video] Saved video to {video_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Convert rewards to NumPy arrays for plotting\n",
    "    total_rewards_np = np.array(total_rewards)\n",
    "    reward_components_np = {k: np.array(v) for k, v in reward_components.items()}\n",
    "    \n",
    "    # Define the PDF filename with current_step\n",
    "    pdf_filename = plot_path / f\"reward_plots_step_{current_step}.pdf\"\n",
    "    \n",
    "    # Create a PdfPages object to save multiple plots into a single PDF\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        # -------------------- First Page: All Functions --------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(total_rewards_np, label=\"Total Reward\", color=\"blue\")\n",
    "        for k, v in reward_components_np.items():\n",
    "            plt.plot(v, label=k)\n",
    "        plt.xlabel(\"Step\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.title(f\"Total and Reward Components Over Time (Checkpoint {current_step})\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()  # Save the current figure into the PDF\n",
    "        plt.close()\n",
    "        print(f\"[Plot] Added all functions plot to PDF: {pdf_filename}\")\n",
    "        \n",
    "        # -------------------- Subsequent Pages: Individual Costs --------------------\n",
    "        for k, v in reward_components_np.items():\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.plot(v, label=k, color=\"green\")\n",
    "            plt.xlabel(\"Step\")\n",
    "            plt.ylabel(f\"Reward Component: {k}\")\n",
    "            plt.title(f\"Reward Component '{k}' Over Time (Checkpoint {current_step})\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()  # Save each individual plot into the PDF\n",
    "            plt.close()\n",
    "            #print(f\"[Plot] Added individual cost '{k}' to PDF: {pdf_filename}\")\n",
    "    \n",
    "    print(f\"[Plot] Saved all reward plots to PDF: {pdf_filename}\")\n",
    "    print(\"[Evaluation] Reward plotting completed.\")\n",
    "\n",
    "\n",
    "    # # -------------------- 8. Plot and Save Rewards --------------------\n",
    "    # print(\"[Evaluation] Plotting rewards...\")\n",
    "\n",
    "    # # Convert rewards to NumPy arrays for plotting\n",
    "    # total_rewards_np = np.array(total_rewards)\n",
    "    # reward_components_np = {k: np.array(v) for k, v in reward_components.items()}\n",
    "\n",
    "    # # Define the plot filename with current_step\n",
    "    # plot_filename_total = plot_path / f\"total_reward_step_{current_step}.pdf\"\n",
    "    # plot_filename_components = plot_path / f\"reward_components_step_{current_step}.pdf\"\n",
    "\n",
    "    # # Plot Total Reward Over Time\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(total_rewards_np, label=\"Total Reward\", color=\"blue\")\n",
    "    # plt.xlabel(\"Step\")\n",
    "    # plt.ylabel(\"Total Reward\")\n",
    "    # plt.title(f\"Total Reward Over Time (Checkpoint {current_step})\")\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(plot_filename_total)\n",
    "    # plt.close()\n",
    "    # print(f\"[Plot] Saved total reward plot to {plot_filename_total}\")\n",
    "\n",
    "    # # Plot Individual Reward Components Over Time\n",
    "    # plt.figure(figsize=(14, 8))\n",
    "    # for k, v in reward_components_np.items():\n",
    "    #     plt.plot(v, label=k)\n",
    "    # plt.xlabel(\"Step\")\n",
    "    # plt.ylabel(\"Reward Component Value\")\n",
    "    # plt.title(f\"Individual Reward Components Over Time (Checkpoint {current_step})\")\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(plot_filename_components)\n",
    "    # plt.close()\n",
    "    # print(f\"[Plot] Saved reward components plot to {plot_filename_components}\")\n",
    "\n",
    "    # print(\"[Evaluation] Reward plotting completed.\")\n",
    "\n",
    "\n",
    "def progress(num_steps, metrics):\n",
    "    print(f'step: {num_steps}  reward: {metrics[\"eval/episode_reward\"]:.3f}')\n",
    "    times.append(datetime.now())\n",
    "    x_data.append(num_steps)\n",
    "    y_data.append(metrics[\"eval/episode_reward\"])\n",
    "    ydataerr.append(metrics[\"eval/episode_reward_std\"])\n",
    "\n",
    "    plt.xlim([0, train_fn.keywords[\"num_timesteps\"] * 1.25])\n",
    "    plt.ylim([min_y, max_y])\n",
    "\n",
    "    plt.xlabel(\"# environment steps\")\n",
    "    plt.ylabel(\"reward per episode\")\n",
    "    plt.title(f\"y={y_data[-1]:.3f}\")\n",
    "\n",
    "    plt.errorbar(x_data, y_data, yerr=ydataerr)\n",
    "    fout = f\"/tmp/quadrupred_joystick/plots/plot_{num_steps}.png\"\n",
    "    print(f\"[Evaluation] Saving plot to {fout}\")\n",
    "    plt.savefig(fout)\n",
    "\n",
    "\n",
    "train_fn = functools.partial(\n",
    "    ppo.train,\n",
    "    # num_timesteps=100_000_000,\n",
    "    num_timesteps=100_000_000,\n",
    "    num_evals=100,\n",
    "    reward_scaling=1,\n",
    "    episode_length=1000,\n",
    "    normalize_observations=True,\n",
    "    action_repeat=1,\n",
    "    unroll_length=20,\n",
    "    num_minibatches=32,\n",
    "    num_updates_per_batch=4,\n",
    "    discounting=0.97,\n",
    "    learning_rate=3.0e-4,\n",
    "    entropy_cost=1e-2,\n",
    "    num_envs=int(8192 / 2),\n",
    "    batch_size=128,\n",
    "    network_factory=make_networks_factory,\n",
    "    randomization_fn=domain_randomize,\n",
    "    policy_params_fn=policy_params_fn,\n",
    "    # restore_checkpoint_path= '/tmp/quadrupred_joystick/ckpts/88883200',\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "\n",
    "# train_fn = functools.partial(\n",
    "#     ppo.train,\n",
    "#     num_timesteps=200_000_000,\n",
    "#     # num_timesteps=100_000,\n",
    "#     num_evals=10,\n",
    "#     reward_scaling=1,\n",
    "#     episode_length=1000/2,\n",
    "#     normalize_observations=True,\n",
    "#     action_repeat=1,\n",
    "#     unroll_length=24,\n",
    "#     num_minibatches=32,\n",
    "#     num_updates_per_batch=4,\n",
    "#     discounting=0.99,\n",
    "#     learning_rate=3.0e-4,\n",
    "#     entropy_cost=1e-2,\n",
    "#     num_envs=int(8192 / 2),\n",
    "#     batch_size=128,\n",
    "#     network_factory=make_networks_factory,\n",
    "#     randomization_fn=domain_randomize,\n",
    "#     policy_params_fn=policy_params_fn,\n",
    "#     # restore_checkpoint_path= '/tmp/quadrupred_joystick/ckpts/88883200',\n",
    "#     seed=0,\n",
    "# )\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "times = [datetime.now()]\n",
    "max_y, min_y = 40, 0\n",
    "\n",
    "\n",
    "make_inference_fn, params, _ = train_fn(\n",
    "    environment=env, progress_fn=progress, eval_env=eval_env\n",
    ")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
